{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor\n",
    "\n",
    "- scalar : dim = 0\n",
    "- vector : dim = 1\n",
    "- matrix : dim = 2\n",
    "- tensor : dim >= 3\n",
    "\n",
    "### Tabular Dataset\n",
    "\n",
    "- 테이블 형태의 데이터셋 (ex) Excel\n",
    "- 각 sample = row, 각 feature = col\n",
    "- N개의 데이터, n개의 특징, k개 sampling\n",
    "- N * n $\\rightarrow$ k * n\n",
    "\n",
    "### Natural Sentence Dataset\n",
    "\n",
    "- 각 sample = Sentences, 각 features = Word(tokens), 각 단어의 embedding vector\n",
    "- N개 문장이 가진 word개 마다의 embedding vector(d) 표현\n",
    "- N * l * d\n",
    "\n",
    "### Computer Vision\n",
    "\n",
    "- 각 sample = Images, 각 pixel마다 값 (W * H), channels RGB 값\n",
    "- N개의 이미지, Width, Height, Channels 데이터\n",
    "- N * W * H * C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "source": [
    "ft = torch.FloatTensor([[1,2],\n",
    "                        [3,4]])\n",
    "\n",
    "print(ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 7.1466e-44]])\n"
     ]
    }
   ],
   "source": [
    "# 임의의 값으로 채워진 원하는 크기의 텐서 생성\n",
    "\n",
    "x = torch.FloatTensor(3,2)\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1,2],\n",
    "              [3,4]])\n",
    "\n",
    "print(x, type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32) <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "x = torch.from_numpy(x)\n",
    "\n",
    "print(x, type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "x = x.numpy()\n",
    "\n",
    "print(x, type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.,  2.],\n",
      "         [ 3.,  4.]],\n",
      "\n",
      "        [[ 5.,  6.],\n",
      "         [ 7.,  8.]],\n",
      "\n",
      "        [[ 9., 10.],\n",
      "         [11., 12.]]]) torch.Size([3, 2, 2])\n",
      "torch.Size([3, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "### Tensor Size\n",
    "\n",
    "x = torch.FloatTensor([[[1,2],\n",
    "                       [3,4]],\n",
    "                       [[5,6],\n",
    "                       [7,8]],\n",
    "                       [[9,10],\n",
    "                        [11,12]]])\n",
    "\n",
    "print(x, x.size())\n",
    "print(x.shape)\n",
    "\n",
    "## size와 shape의 차이는 없으며, size함수의 결과 값이 shape 속성에 담겨 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 4.],\n",
      "        [6., 7.]])\n",
      "tensor([[-1.,  0.],\n",
      "        [ 0.,  1.]])\n",
      "tensor([[ 2.,  4.],\n",
      "        [ 9., 12.]])\n",
      "tensor([[0.5000, 1.0000],\n",
      "        [1.0000, 1.3333]])\n",
      "tensor([[ 1.,  4.],\n",
      "        [27., 64.]])\n"
     ]
    }
   ],
   "source": [
    "### 산술 연산\n",
    "\n",
    "a = torch.FloatTensor([[1,2],\n",
    "                       [3,4]])\n",
    "b = torch.FloatTensor([[2,2],\n",
    "                       [3,3]])\n",
    "\n",
    "print(a+b)\n",
    "print(a-b)\n",
    "print(a*b)\n",
    "print(a/b)\n",
    "print(a**b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([[ 2.,  4.],\n",
      "        [ 9., 12.]])\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([[ 2.,  4.],\n",
      "        [ 9., 12.]])\n",
      "tensor([[ 2.,  4.],\n",
      "        [ 9., 12.]])\n"
     ]
    }
   ],
   "source": [
    "### inplace operation\n",
    "#### 기존 연산자의 경우 결과를 새롭게 메모리 할당\n",
    "#### inplace는 기존 연산자와 동일하되 기존 텐서에 결과가 저장됨\n",
    "\n",
    "print(a)\n",
    "print(a.mul(b)) # 기존 곱셈 함수\n",
    "print(a)\n",
    "print(a.mul_(b)) # inplace 곱셈 함수\n",
    "print(a)\n",
    "\n",
    "# garbage collector가 효율적으로 동작, 굳이 사용할 필요 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Dim change\n",
    "\n",
    "- View function\n",
    "    - 기존의 텐서 요소와 일치하되, 원하는 크기 요소로 수정 가능\n",
    "    - -1의 경우, 모두 곱하고 남은 요소로 자동으로 채워짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[          7,   842347317],\n",
      "         [          0,           0]],\n",
      "\n",
      "        [[-1798258096,         496],\n",
      "         [-1798258096,         496]]], dtype=torch.int32)\n",
      "tensor([[[          7,   842347317],\n",
      "         [          0,           0],\n",
      "         [-1798258096,         496],\n",
      "         [-1798258096,         496]]], dtype=torch.int32)\n",
      "tensor([[[          7,   842347317],\n",
      "         [          0,           0],\n",
      "         [-1798258096,         496],\n",
      "         [-1798258096,         496]]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "x = torch.IntTensor(2,2,2)\n",
    "\n",
    "print(x)\n",
    "print(x.view(1,4,2))\n",
    "print(x.view(1,-1,2))\n",
    "\n",
    "### view의 결과는 tensor의 주소를 바꾸지 않음\n",
    "### 단 view의 경우 contiguous Tensor에 대해서만 작동(메모리에 순차적으로 선언된 텐서에 대해서만 작동)\n",
    "### 따라서 error가 나올 경우, contiguous() 함수로 인접한 주소에 인접한 값을 순서대로 할당\n",
    "### reshape의 경우 위와 같은 작업 contiguous -> view를 순차적으로 처리\n",
    "### 주의) reshape의 경우 contiguous를 호출한 후 수행하기 때문에 기존 주소와 다를 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Squeeze\n",
    "\n",
    "- 차원의 크기가 1인 차원을 없애주는 역할\n",
    "- 만약 해당 차원의 크기가 1인 아닌 경우, 같은 텐서가 반환\n",
    "\n",
    "#### UnSqueeze\n",
    "\n",
    "- 지정된 차원의 인덱스에 차원의 크기가 1인 차원을 삽입\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 2])\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([[[1,2],\n",
    "                       [3,4]]])\n",
    "\n",
    "print(x.size())\n",
    "\n",
    "print(x.squeeze().size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 2, 2])\n",
      "torch.Size([1, 2, 2, 1])\n",
      "torch.Size([2, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([[[1,2],\n",
    "                       [3,4]]])\n",
    "\n",
    "print(x.unsqueeze(1).size())\n",
    "print(x.unsqueeze(-1).size())\n",
    "print(x.reshape(2,2,-1).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split, Chunk Function\n",
    "\n",
    "- split function의 경우 안의 개수를 지정\n",
    "- chunk function의 경우 그룹 개수를 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 4])\n",
      "torch.Size([4, 4])\n",
      "torch.Size([4, 4])\n",
      "torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor(10,4)\n",
    "\n",
    "print(x.size())\n",
    "\n",
    "splits = x.split(4, dim=0) # 원소 수\n",
    "\n",
    "for s in splits:\n",
    "    print(s.size())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 4])\n",
      "torch.Size([4, 4])\n",
      "torch.Size([4, 4])\n",
      "torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor(10, 4)\n",
    "\n",
    "print(x.size())\n",
    "\n",
    "chunks = x.chunk(3, dim=0) # group 수\n",
    "\n",
    "for c in chunks:\n",
    "    print(c.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate\n",
    "\n",
    "- cat function : 두 차원을 이어붙이는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3]) torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([[1,2,3],\n",
    "                       [4,5,6],\n",
    "                       [7,8,9]])\n",
    "y = torch.FloatTensor([[10,11,12],\n",
    "                       [13,14,15],\n",
    "                       [16,17,18]])\n",
    "\n",
    "print(x.size(), y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 3])\n",
      "torch.Size([3, 6])\n"
     ]
    }
   ],
   "source": [
    "z = torch.cat([x,y], dim=0) # 행 방향으로 concat\n",
    "\n",
    "print(z.size())\n",
    "\n",
    "print(torch.cat([x,y], dim=-1).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stack, 쌓기 함수\n",
    "\n",
    "- cat은 차원을 유지한채 이어붙이는 작업\n",
    "- stack은 차원을 하나 늘려 쌓는 작업\n",
    "\n",
    "- unsqueeze(-1) -> cat 과 동일한 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 3])\n",
      "torch.Size([2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(torch.stack([x,y]).size())\n",
    "print(torch.cat([x.unsqueeze(0), y.unsqueeze(0)]).size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expand function\n",
    "\n",
    "- dim = 1인 차원을 원하는 크기로 늘려주는 역할\n",
    "- 동일한 텐서를 반복하여 list에 넣고, cat 함수를 해당 차원에 대해서 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([[[1,2]],\n",
    "                       [[3,4]]])\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 2])\n",
      "torch.Size([2, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "y = x.expand(2,3,2)\n",
    "\n",
    "print(y.size())\n",
    "\n",
    "print(torch.cat([x] * 3, dim=1).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Permutation, Argument Max function\n",
    "\n",
    "- random permutation : 랜덤 수열 생성 함수 (param = 10, 1 ~ param까지 수 랜덤 생성)\n",
    "- Argument Max : set X에서 뽑을 수 있는 x 값 중 함수 f의 출력 값을 최대로 만드는 입력 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 7,  6, 22],\n",
      "         [26,  1, 23],\n",
      "         [24,  2, 14]],\n",
      "\n",
      "        [[17, 10,  0],\n",
      "         [ 3,  8, 18],\n",
      "         [12,  9, 11]],\n",
      "\n",
      "        [[25, 16, 19],\n",
      "         [13,  5, 20],\n",
      "         [ 4, 21, 15]]])\n",
      "tensor([[2, 0, 0],\n",
      "        [0, 2, 0],\n",
      "        [0, 2, 1]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randperm(3**3).reshape(3,3,-1)\n",
    "\n",
    "print(x)\n",
    "\n",
    "y = x.argmax(dim=-1) # dim=-1의 경우, 같은 위치의 다른 데이터셋에서 가장 큰 값의 인덱스 출력\n",
    "\n",
    "print(y)\n",
    "\n",
    "### 0,0 -> 0번째 set에서 0번째 행 중 가장 큰 값의 인덱스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[22,  7],\n",
      "         [26, 23],\n",
      "         [24, 14]],\n",
      "\n",
      "        [[17, 10],\n",
      "         [18,  8],\n",
      "         [12, 11]],\n",
      "\n",
      "        [[25, 19],\n",
      "         [20, 13],\n",
      "         [21, 15]]]) torch.Size([3, 3, 2])\n",
      "tensor([[[2, 0],\n",
      "         [0, 2],\n",
      "         [0, 2]],\n",
      "\n",
      "        [[0, 1],\n",
      "         [2, 1],\n",
      "         [0, 2]],\n",
      "\n",
      "        [[0, 2],\n",
      "         [2, 0],\n",
      "         [1, 2]]]) torch.Size([3, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "values, indices = torch.topk(x, k=2, dim=-1) # 열에 대해 가장 큰 값\n",
    "print(values, values.size())\n",
    "print(indices, indices.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ones & Zeros\n",
    "\n",
    "- 상수로 이뤄진 tensor를 생성 : torch.ones(2,3)\n",
    "- 0으로 이뤄진 tensor를 생성 : torch.zeros(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.zeros(2,3))\n",
    "print(torch.ones(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([[1,2,3],\n",
    "                       [4,5,6]])\n",
    "\n",
    "print(x)\n",
    "\n",
    "# 특정 tensor와 동일한 크기의 상수, 0의 텐서를 생성할 수 있음\n",
    "print(torch.ones_like(x))\n",
    "\n",
    "print(torch.zeros_like(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
