{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Transformer 구현\n",
    "## nn.Transformer 모듈을 이용하는 Seq2Seq 모델 학습\n",
    "### NLP에서 큰 영향을 준 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 언어 모델링 과제에 대해 학습\n",
    "## 언어 모델링 과제 = 주어진 단어가 다음에 이어지는 단어 시퀀스를 따를 가능성 (Likelihood)에 대한 확률을 할당하는 것\n",
    "## token(seqence) -> embedding -> positional encoding -> 미래 token에 대해서는 몰라야하기 때문에 masking\n",
    "### 최종적으로 얻는 단어는 log-softmax로 Linear 레이어로 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "from tempfile import TemporaryDirectory\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import dataset\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int,\n",
    "                 nlayers: int, dropout: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = nn.Embedding(ntoken, d_model)\n",
    "        self.d_model = d_model\n",
    "        self.decoder = nn.Linear(d_model, ntoken)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src: Tensor, src_mask: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Arguemnts:\n",
    "            src : Tensor, shape ``[seq_len, batch_size] ``\n",
    "            src_mask : Tensor, shape ``[seq_len, seq_len] ``\n",
    "\n",
    "        Returns :\n",
    "            output Tensor of shape ``[seq_len, batch_size, ntoken]``\n",
    "        \"\"\"\n",
    "\n",
    "        src = self.encoder(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src) # positional encoder\n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        output = self.decoder(output)\n",
    "        return output\n",
    "    \n",
    "def generate_square_subsequent_mask(sz: int) -> Tensor:\n",
    "    \"\"\" Generates an upper-triangular matrix of ``-inf``, with zeros on ``diag``.\"\"\"\n",
    "    return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)\n",
    "\n",
    "print(generate_square_subsequent_mask(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positional embedding 함수, cosin, sin 함수 사용\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float=0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term) # 짝수는 sin 주파수\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)  # 홀수는 cos 주파수\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x : Tensor, shape ``[seq_len, batch_size, embedding_dim] ``\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torchdata\n",
    "\n",
    "# vocab 객체는 훈련 데이터셋에 의해 만들어지고,\n",
    "# token을 텐서로 수치화 하는데 사용됨\n",
    "## rare token(보기 드문 토큰)은 <unk>로 표현됨\n",
    "\n",
    "# batchify() 함수 : 데이터를 batch_size 컬럼들로 정렬\n",
    "## 만약, batch_size 컬럼으로 나눠 떨어지지 않으면, 데이터를 잘라서 맞춤\n",
    "## ex) A ~ Z(26자) -> batch_size = 4 -> [[A, B, * 6],[6],[6],[6]] 나눠짐\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"wikitext\", \"wikitext-2-v1\")\n",
    "\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "train_iter = dataset['train']['text']\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for text in data_iter: # (text)\n",
    "        yield tokenizer(text)\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=['<unk>'])\n",
    "vocab.set_default_index(vocab['<unk>'])\n",
    "\n",
    "def data_process(raw_text_iter) -> Tensor:\n",
    "    \"\"\" Converts raw text into a float Tensor. \"\"\"\n",
    "    data = [torch.tensor(vocab(tokenizer(item)), dtype=torch.long) for item in raw_text_iter]\n",
    "    # cat -> tensor 연결\n",
    "    # filter -> lambda 함수에 해당하는 것만 필터링\n",
    "    # t.numel()은 tensor의 요소가 몇 개인지, 하나 이상인 텐서만 선택\n",
    "    return torch.cat(tuple(filter(lambda t: t.numel() > 0, data)))\n",
    "\n",
    "\n",
    "train_iter, val_iter, test_iter = dataset['train']['text'], dataset['validation']['text'], dataset['test']['text']\n",
    "train_data = data_process(train_iter)\n",
    "val_data = data_process(val_iter)\n",
    "test_data = data_process(test_iter)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify(data: Tensor, bsz: int) -> Tensor:\n",
    "    \"\"\"\n",
    "    Divides the data into ``bsz`` separate sequences, removing extra elements\n",
    "    that wouldn't cleanly fit.\n",
    "\n",
    "    Arguments:\n",
    "        data : Tensor, shape ``[N]``\n",
    "        bsz : int, batch size\n",
    "\n",
    "    Returns:\n",
    "        Tensor of shape ``[N // bsz, bsz]```\n",
    "    \"\"\"\n",
    "    seq_len = data.size(0) // bsz\n",
    "    data = data[:seq_len * bsz]\n",
    "    data = data.view(bsz, seq_len).t().contiguous()\n",
    "    return data.to(device)\n",
    "\n",
    "batch_size = 20 # batch_size = 20\n",
    "eval_batch_size = 10\n",
    "train_data = batchify(train_data, batch_size) # shapep [seq_len, batch_size]\n",
    "val_data = batchify(val_data, eval_batch_size)\n",
    "test_data = batchify(test_data, eval_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get_batch : input-target sequence pair를 생성\n",
    "## source data를 bptt 길이를 가진 덩어리로 세분화\n",
    "\n",
    "bptt = 35\n",
    "\n",
    "def get_batch(source: Tensor, i: int) -> Tuple[Tensor, Tensor]:\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        source: Tensor, shape ``[full_seq_len, batch_size]``\n",
    "        i: int\n",
    "\n",
    "    Returns:\n",
    "        tuple ``(data, target)``, where data has shape ``[seq_len, batch_size]`` and\n",
    "        target has shape ``[seq_len * batch_size]``\n",
    "    \"\"\"\n",
    "    seq_len = min(bptt, len(source) - 1 - i)\n",
    "    data = source[i:i+seq_len] # 앞에 i부터 ~ seq_len 만큼 자름\n",
    "    target = source[i+1:i+1+seq_len].reshape(-1) # i+1부터 ~ seq_len + 1 만큼 예측\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntokens = len(vocab) # 단어 사전(어휘집)의 크기\n",
    "emsize = 200 # 임베딩 차원\n",
    "d_hid = 200 # ``nn.TransformerEncoder`` 에서 피드포워드 네트워크(feedforward network) 모델의 차원\n",
    "nlayers = 2 # ``nn.TransformerEncoder`` 내부의 nn.TransformerEncoderLayer 개수 encoder 2계층\n",
    "nhead = 2 # ``nn.MultiheadAttention`` 의 헤드 개수 # 2-heads attentions\n",
    "dropout = 0.2 # 드랍아웃(dropout) 확률\n",
    "model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 5.0  # 학습률(learning rate)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "# step size마다 gamma 비율로 lr을 감소시킴, step_size = 1.0\n",
    "\n",
    "def train(model: nn.Module) -> None:\n",
    "    model.train()  # 학습 모드 시작\n",
    "    total_loss = 0.\n",
    "    log_interval = 200\n",
    "    start_time = time.time()\n",
    "    src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
    "\n",
    "    num_batches = len(train_data) // bptt\n",
    "    for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n",
    "        data, targets = get_batch(train_data, i)\n",
    "        seq_len = data.size(0)\n",
    "        if seq_len != bptt:  # 마지막 배치에만 적용(다른 배치는 bptt길이)\n",
    "            src_mask = src_mask[:seq_len, :seq_len]\n",
    "        output = model(data, src_mask)\n",
    "        loss = criterion(output.view(-1, ntokens), targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        # 기울기 폭발 방지\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "            cur_loss = total_loss / log_interval\n",
    "            ppl = math.exp(cur_loss)\n",
    "            print(f'| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | '\n",
    "                  f'lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | '\n",
    "                  f'loss {cur_loss:5.2f} | ppl {ppl:8.2f}')\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(model: nn.Module, eval_data: Tensor) -> float:\n",
    "    model.eval()  # 평가 모드 시작\n",
    "    total_loss = 0.\n",
    "    src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, eval_data.size(0) - 1, bptt):\n",
    "            data, targets = get_batch(eval_data, i)\n",
    "            seq_len = data.size(0)\n",
    "            if seq_len != bptt:\n",
    "                src_mask = src_mask[:seq_len, :seq_len]\n",
    "            output = model(data, src_mask)\n",
    "            output_flat = output.view(-1, ntokens)\n",
    "            total_loss += seq_len * criterion(output_flat, targets).item()\n",
    "    return total_loss / (len(eval_data) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   200/ 2928 batches | lr 5.00 | ms/batch 22.69 | loss  8.23 | ppl  3749.85\n",
      "| epoch   1 |   400/ 2928 batches | lr 5.00 | ms/batch 15.44 | loss  6.92 | ppl  1013.94\n",
      "| epoch   1 |   600/ 2928 batches | lr 5.00 | ms/batch 14.61 | loss  6.46 | ppl   639.96\n",
      "| epoch   1 |   800/ 2928 batches | lr 5.00 | ms/batch 12.64 | loss  6.32 | ppl   556.14\n",
      "| epoch   1 |  1000/ 2928 batches | lr 5.00 | ms/batch 12.25 | loss  6.20 | ppl   492.59\n",
      "| epoch   1 |  1200/ 2928 batches | lr 5.00 | ms/batch 14.27 | loss  6.16 | ppl   473.87\n",
      "| epoch   1 |  1400/ 2928 batches | lr 5.00 | ms/batch 13.26 | loss  6.12 | ppl   453.83\n",
      "| epoch   1 |  1600/ 2928 batches | lr 5.00 | ms/batch 14.13 | loss  6.11 | ppl   448.82\n",
      "| epoch   1 |  1800/ 2928 batches | lr 5.00 | ms/batch 13.32 | loss  6.04 | ppl   418.16\n",
      "| epoch   1 |  2000/ 2928 batches | lr 5.00 | ms/batch 12.95 | loss  6.03 | ppl   415.20\n",
      "| epoch   1 |  2200/ 2928 batches | lr 5.00 | ms/batch 12.43 | loss  5.90 | ppl   365.99\n",
      "| epoch   1 |  2400/ 2928 batches | lr 5.00 | ms/batch 12.46 | loss  5.96 | ppl   388.94\n",
      "| epoch   1 |  2600/ 2928 batches | lr 5.00 | ms/batch 12.46 | loss  5.95 | ppl   383.55\n",
      "| epoch   1 |  2800/ 2928 batches | lr 5.00 | ms/batch 12.54 | loss  5.88 | ppl   358.06\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 42.06s | valid loss  5.80 | valid ppl   328.78\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   2 |   200/ 2928 batches | lr 4.75 | ms/batch 12.42 | loss  5.87 | ppl   353.55\n",
      "| epoch   2 |   400/ 2928 batches | lr 4.75 | ms/batch 12.56 | loss  5.86 | ppl   351.91\n",
      "| epoch   2 |   600/ 2928 batches | lr 4.75 | ms/batch 12.64 | loss  5.68 | ppl   292.25\n",
      "| epoch   2 |   800/ 2928 batches | lr 4.75 | ms/batch 12.69 | loss  5.71 | ppl   302.50\n",
      "| epoch   2 |  1000/ 2928 batches | lr 4.75 | ms/batch 13.84 | loss  5.66 | ppl   287.48\n",
      "| epoch   2 |  1200/ 2928 batches | lr 4.75 | ms/batch 13.50 | loss  5.69 | ppl   295.24\n",
      "| epoch   2 |  1400/ 2928 batches | lr 4.75 | ms/batch 14.26 | loss  5.69 | ppl   297.17\n",
      "| epoch   2 |  1600/ 2928 batches | lr 4.75 | ms/batch 15.04 | loss  5.71 | ppl   303.04\n",
      "| epoch   2 |  1800/ 2928 batches | lr 4.75 | ms/batch 14.53 | loss  5.65 | ppl   284.93\n",
      "| epoch   2 |  2000/ 2928 batches | lr 4.75 | ms/batch 14.09 | loss  5.67 | ppl   290.93\n",
      "| epoch   2 |  2200/ 2928 batches | lr 4.75 | ms/batch 14.00 | loss  5.56 | ppl   259.79\n",
      "| epoch   2 |  2400/ 2928 batches | lr 4.75 | ms/batch 14.07 | loss  5.65 | ppl   285.06\n",
      "| epoch   2 |  2600/ 2928 batches | lr 4.75 | ms/batch 14.08 | loss  5.65 | ppl   284.57\n",
      "| epoch   2 |  2800/ 2928 batches | lr 4.75 | ms/batch 14.08 | loss  5.58 | ppl   265.98\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 41.79s | valid loss  5.67 | valid ppl   290.53\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   3 |   200/ 2928 batches | lr 4.51 | ms/batch 14.05 | loss  5.61 | ppl   273.62\n",
      "| epoch   3 |   400/ 2928 batches | lr 4.51 | ms/batch 14.14 | loss  5.63 | ppl   279.37\n",
      "| epoch   3 |   600/ 2928 batches | lr 4.51 | ms/batch 13.98 | loss  5.42 | ppl   226.89\n",
      "| epoch   3 |   800/ 2928 batches | lr 4.51 | ms/batch 12.56 | loss  5.49 | ppl   241.79\n",
      "| epoch   3 |  1000/ 2928 batches | lr 4.51 | ms/batch 12.47 | loss  5.45 | ppl   231.88\n",
      "| epoch   3 |  1200/ 2928 batches | lr 4.51 | ms/batch 12.56 | loss  5.48 | ppl   239.67\n",
      "| epoch   3 |  1400/ 2928 batches | lr 4.51 | ms/batch 12.62 | loss  5.51 | ppl   245.95\n",
      "| epoch   3 |  1600/ 2928 batches | lr 4.51 | ms/batch 12.67 | loss  5.53 | ppl   252.54\n",
      "| epoch   3 |  1800/ 2928 batches | lr 4.51 | ms/batch 12.61 | loss  5.48 | ppl   238.75\n",
      "| epoch   3 |  2000/ 2928 batches | lr 4.51 | ms/batch 12.63 | loss  5.49 | ppl   242.73\n",
      "| epoch   3 |  2200/ 2928 batches | lr 4.51 | ms/batch 12.63 | loss  5.36 | ppl   213.22\n",
      "| epoch   3 |  2400/ 2928 batches | lr 4.51 | ms/batch 12.71 | loss  5.47 | ppl   238.35\n",
      "| epoch   3 |  2600/ 2928 batches | lr 4.51 | ms/batch 12.61 | loss  5.48 | ppl   240.85\n",
      "| epoch   3 |  2800/ 2928 batches | lr 4.51 | ms/batch 12.61 | loss  5.41 | ppl   223.71\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 39.20s | valid loss  5.54 | valid ppl   255.95\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float('inf')\n",
    "epochs = 3\n",
    "\n",
    "with TemporaryDirectory() as tempdir:\n",
    "    best_model_params_path = os.path.join(tempdir, \"best_model_params.pt\")\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        train(model)\n",
    "        val_loss = evaluate(model, val_data)\n",
    "        val_ppl = math.exp(val_loss)\n",
    "        elapsed = time.time() - epoch_start_time\n",
    "        print('-' * 89)\n",
    "        print(f'| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | '\n",
    "            f'valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}')\n",
    "        print('-' * 89)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "        scheduler.step()\n",
    "    model.load_state_dict(torch.load(best_model_params_path)) # load best model states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss  5.46 | test ppl   234.87\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "test_loss = evaluate(model, test_data)\n",
    "test_ppl = math.exp(test_loss)\n",
    "print('=' * 89)\n",
    "print(f'| End of training | test loss {test_loss:5.2f} | '\n",
    "      f'test ppl {test_ppl:8.2f}')\n",
    "print('=' * 89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
