{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EfficientNet 코드 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EfficientNet-B0 Baseline network\n",
    "## 1st = Conv 3*3\n",
    "## 2nd = MBConv1, k3*3\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "from torchsummary import summary\n",
    "from torch import optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SE Block\n",
    "\n",
    "# squeeze and Excitation\n",
    "# reduction_ratio = 0.25 (감소 비율)\n",
    "# H X W X C -> 1 X 1 X C 로 펴준다음 다시 H X W X C로 바꿔주면서 각 채널마다 가중치 추가\n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, in_channels, r=0.25):\n",
    "        super().__init__()\n",
    "\n",
    "        # C / r을 계산하는 변수\n",
    "        # se_channels : reduce layer out channels 계산\n",
    "        se_channels = max(1, int(in_channels*r))\n",
    "\n",
    "        self.se = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1), # Global AvgPooling\n",
    "            nn.Conv2d(in_channels, se_channels, kernel_size=1), # 1*1 conv\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(se_channels, in_channels, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.se(x) # 가중치가 적용된 각각의 필터가 나옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.4125, 0.3502, 0.4754],\n",
      "         [0.2715, 0.4367, 0.5194],\n",
      "         [0.0860, 0.3861, 0.4219]]])\n",
      "tensor([[[0.3733]]])\n"
     ]
    }
   ],
   "source": [
    "input = torch.rand(1, 3, 3)\n",
    "print(input)\n",
    "maxp = nn.AdaptiveAvgPool2d((1,1)) # 내가 원하는 크기의 pooling을 계산\n",
    "output = maxp(input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MBConv Block\n",
    "## MobileNetv2 개념을 가져옴\n",
    "# 1st Expantion\n",
    "# 2nd Depth-wise Convolution\n",
    "# 3rd Point-wise Convolution\n",
    "# 4th Skip Connection\n",
    "\n",
    "## 차이점\n",
    "# LeRU6 대신 SiLU\n",
    "# Depth-wise, Point-wise 사이 SE 사용\n",
    "# Depth-wise 수행시 kernel_size를 3 or 5 사용\n",
    "\n",
    "# 최종 모델\n",
    "# 1st Expantion\n",
    "# 2nd Depth-wise Convolution\n",
    "# 2nd_1 : SEBlock\n",
    "# 3rd Point-wise Convolution\n",
    "# 4th Skip Connection\n",
    "\n",
    "class MBConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, expand, kernel_size, stride=1, r=0.25, dropout_rate=0.2, bias=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # parameter 설정\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.expand = expand\n",
    "\n",
    "        # skip connection 사용 조건\n",
    "        self.use_residual = (in_channels == out_channels) and (stride == 1)\n",
    "\n",
    "        # paper에서 수행한 BatchNorm, SiLU 적용\n",
    "        # expand 채널을 늘리는 작업\n",
    "        expand_channels = in_channels*expand\n",
    "        self.expansion = nn.Sequential(nn.Conv2d(in_channels, expand_channels, 1, bias=False),\n",
    "                                       nn.BatchNorm2d(expand_channels, momentum=0.99),\n",
    "                                       nn.SiLU(),\n",
    "                                       )\n",
    "        # Depth-wise Convolution\n",
    "        # groups = 1이면 모든 입력이 모든 출력과 conv 연산,\n",
    "        # 각각의 input channel이 output channel과 대응 연산\n",
    "        self.depth_wise = nn.Sequential(nn.Conv2d(expand_channels, expand_channels, kernel_size=kernel_size, stride=1, padding=1, groups=expand_channels),\n",
    "                                        nn.BatchNorm2d(expand_channels, momentum=0.99),\n",
    "                                        nn.SiLU(),\n",
    "                                        )\n",
    "        # Squeeze and Excitation\n",
    "        self.se_block = SEBlock(expand_channels, r)\n",
    "\n",
    "        # Point-wise Convolution\n",
    "        self.point_wise = nn.Sequential(nn.Conv2d(expand_channels, out_channels, 1, 1, bias=False),\n",
    "                                        nn.BatchNorm2d(out_channels, momentum=0.99),\n",
    "                                        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.expand != 1:\n",
    "            x = self.expansion(x)\n",
    "        \n",
    "        x = self.depth_wise(x)\n",
    "        x = self.se_block(x)\n",
    "        x = self.point_wise(x)\n",
    "\n",
    "        res = x\n",
    "\n",
    "        if self.use_residual:\n",
    "            if self.training and (self.dropout_rate is not None):\n",
    "                x = F.dropout2d(input=x, p=self.dropout_rate, training=self.training, inplace=True)\n",
    "            \n",
    "            x = x + res\n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNet(nn.Module):\n",
    "    def __init__(self, num_classes, width, depth, resolution, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        # stage 1\n",
    "        out_ch = int(32 * width)\n",
    "        self.stage1 = nn.Sequential(nn.Conv2d(in_channels=3, out_channels=out_ch, kernel_size=3, stride=2, padding=1),\n",
    "                                    nn.BatchNorm2d(out_ch, momentum=0.99),\n",
    "                                    )\n",
    "        # 다음 input 이미지가 반으로 줆,\n",
    "        # stride가 2인 이유\n",
    "        \n",
    "        # stage 2\n",
    "        self.stage2 = nn.Sequential(MBConvBlock(in_channels=out_ch, out_channels=16, expand=1, kernel_size=3, stride=1, dropout_rate=dropout))\n",
    "\n",
    "        # stage 3\n",
    "        self.stage3 = nn.Sequential(MBConvBlock(in_channels=16, out_channels=24, expand=6, kernel_size=3, stride=2, dropout_rate=dropout),\n",
    "                                    MBConvBlock(in_channels=24, out_channels=24, expand=6, kernel_size=3, stride=1, dropout_rate=dropout),\n",
    "                                    )\n",
    "        \n",
    "        # stage4\n",
    "        self.stage4 = nn.Sequential(MBConvBlock(in_channels=24, out_channels=40, expand=6, kernel_size=5, stride=2, dropout_rate=dropout),\n",
    "                                    MBConvBlock(in_channels=40, out_channels=40, expand=6, kernel_size=5, stride=1, dropout_rate=dropout),\n",
    "                                   )\n",
    "        \n",
    "        # stage5\n",
    "        self.stage5 = nn.Sequential(MBConvBlock(in_channels=40, out_channels=80, expand=6, kernel_size=3, stride=2, dropout_rate=dropout),\n",
    "                                    MBConvBlock(in_channels=80, out_channels=80, expand=6, kernel_size=3, stride=1, dropout_rate=dropout),\n",
    "                                    MBConvBlock(in_channels=80, out_channels=80, expand=6, kernel_size=3, stride=1, dropout_rate=dropout),\n",
    "                                   )\n",
    "        \n",
    "        # stage6\n",
    "        self.stage6 = nn.Sequential(MBConvBlock(in_channels=80, out_channels=112, expand=6, kernel_size=5, stride=1, dropout_rate=dropout),\n",
    "                                    MBConvBlock(in_channels=112, out_channels=112, expand=6, kernel_size=5, stride=1, dropout_rate=dropout),\n",
    "                                    MBConvBlock(in_channels=112, out_channels=112, expand=6, kernel_size=5, stride=1, dropout_rate=dropout),\n",
    "                                   )\n",
    "        \n",
    "        # stage7\n",
    "        self.stage7 = nn.Sequential(MBConvBlock(in_channels=112, out_channels=192, expand=6, kernel_size=5, stride=2, dropout_rate=dropout),\n",
    "                                    MBConvBlock(in_channels=192, out_channels=192, expand=6, kernel_size=5, stride=1, dropout_rate=dropout),\n",
    "                                    MBConvBlock(in_channels=192, out_channels=192, expand=6, kernel_size=5, stride=1, dropout_rate=dropout),\n",
    "                                    MBConvBlock(in_channels=192, out_channels=192, expand=6, kernel_size=5, stride=1, dropout_rate=dropout),\n",
    "                                   )\n",
    "        \n",
    "        # stage8\n",
    "        self.stage8 = nn.Sequential(MBConvBlock(in_channels=192, out_channels=320, expand=6, kernel_size=3, stride=1, dropout_rate=dropout))\n",
    "        \n",
    "        # stage9\n",
    "        self.last_channels = math.ceil(1280*width)\n",
    "        self.stage9 = nn.Conv2d(in_channels=320, out_channels=self.last_channels, kernel_size=1)\n",
    "        \n",
    "        # result\n",
    "        self.out_layer = nn.Linear(self.last_channels, num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stage1(x)\n",
    "        x = self.stage2(x)\n",
    "        x = self.stage3(x)\n",
    "        x = self.stage4(x)\n",
    "        x = self.stage5(x)\n",
    "        x = self.stage6(x)\n",
    "        x = self.stage7(x)\n",
    "        x = self.stage8(x)\n",
    "        x = self.stage9(x)\n",
    "        x = F.adaptive_avg_pool2d(x, (1,1)).view(-1, self.last_channels)\n",
    "        x = self.out_layer(x)\n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def efficientnet_b0(num_classes=10):\n",
    "    return EfficientNet(num_classes=num_classes, width=1.0, depth=1.0, resolution=224, dropout=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output size: torch.Size([4, 10])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 112, 112]             896\n",
      "       BatchNorm2d-2         [-1, 32, 112, 112]              64\n",
      "            Conv2d-3         [-1, 32, 112, 112]             320\n",
      "       BatchNorm2d-4         [-1, 32, 112, 112]              64\n",
      "              SiLU-5         [-1, 32, 112, 112]               0\n",
      " AdaptiveAvgPool2d-6             [-1, 32, 1, 1]               0\n",
      "            Conv2d-7              [-1, 8, 1, 1]             264\n",
      "              SiLU-8              [-1, 8, 1, 1]               0\n",
      "            Conv2d-9             [-1, 32, 1, 1]             288\n",
      "          Sigmoid-10             [-1, 32, 1, 1]               0\n",
      "          SEBlock-11         [-1, 32, 112, 112]               0\n",
      "           Conv2d-12         [-1, 16, 112, 112]             512\n",
      "      BatchNorm2d-13         [-1, 16, 112, 112]              32\n",
      "      MBConvBlock-14         [-1, 16, 112, 112]               0\n",
      "           Conv2d-15         [-1, 96, 112, 112]           1,536\n",
      "      BatchNorm2d-16         [-1, 96, 112, 112]             192\n",
      "             SiLU-17         [-1, 96, 112, 112]               0\n",
      "           Conv2d-18         [-1, 96, 112, 112]             960\n",
      "      BatchNorm2d-19         [-1, 96, 112, 112]             192\n",
      "             SiLU-20         [-1, 96, 112, 112]               0\n",
      "AdaptiveAvgPool2d-21             [-1, 96, 1, 1]               0\n",
      "           Conv2d-22             [-1, 24, 1, 1]           2,328\n",
      "             SiLU-23             [-1, 24, 1, 1]               0\n",
      "           Conv2d-24             [-1, 96, 1, 1]           2,400\n",
      "          Sigmoid-25             [-1, 96, 1, 1]               0\n",
      "          SEBlock-26         [-1, 96, 112, 112]               0\n",
      "           Conv2d-27         [-1, 24, 112, 112]           2,304\n",
      "      BatchNorm2d-28         [-1, 24, 112, 112]              48\n",
      "      MBConvBlock-29         [-1, 24, 112, 112]               0\n",
      "           Conv2d-30        [-1, 144, 112, 112]           3,456\n",
      "      BatchNorm2d-31        [-1, 144, 112, 112]             288\n",
      "             SiLU-32        [-1, 144, 112, 112]               0\n",
      "           Conv2d-33        [-1, 144, 112, 112]           1,440\n",
      "      BatchNorm2d-34        [-1, 144, 112, 112]             288\n",
      "             SiLU-35        [-1, 144, 112, 112]               0\n",
      "AdaptiveAvgPool2d-36            [-1, 144, 1, 1]               0\n",
      "           Conv2d-37             [-1, 36, 1, 1]           5,220\n",
      "             SiLU-38             [-1, 36, 1, 1]               0\n",
      "           Conv2d-39            [-1, 144, 1, 1]           5,328\n",
      "          Sigmoid-40            [-1, 144, 1, 1]               0\n",
      "          SEBlock-41        [-1, 144, 112, 112]               0\n",
      "           Conv2d-42         [-1, 24, 112, 112]           3,456\n",
      "      BatchNorm2d-43         [-1, 24, 112, 112]              48\n",
      "      MBConvBlock-44         [-1, 24, 112, 112]               0\n",
      "           Conv2d-45        [-1, 144, 112, 112]           3,456\n",
      "      BatchNorm2d-46        [-1, 144, 112, 112]             288\n",
      "             SiLU-47        [-1, 144, 112, 112]               0\n",
      "           Conv2d-48        [-1, 144, 110, 110]           3,744\n",
      "      BatchNorm2d-49        [-1, 144, 110, 110]             288\n",
      "             SiLU-50        [-1, 144, 110, 110]               0\n",
      "AdaptiveAvgPool2d-51            [-1, 144, 1, 1]               0\n",
      "           Conv2d-52             [-1, 36, 1, 1]           5,220\n",
      "             SiLU-53             [-1, 36, 1, 1]               0\n",
      "           Conv2d-54            [-1, 144, 1, 1]           5,328\n",
      "          Sigmoid-55            [-1, 144, 1, 1]               0\n",
      "          SEBlock-56        [-1, 144, 110, 110]               0\n",
      "           Conv2d-57         [-1, 40, 110, 110]           5,760\n",
      "      BatchNorm2d-58         [-1, 40, 110, 110]              80\n",
      "      MBConvBlock-59         [-1, 40, 110, 110]               0\n",
      "           Conv2d-60        [-1, 240, 110, 110]           9,600\n",
      "      BatchNorm2d-61        [-1, 240, 110, 110]             480\n",
      "             SiLU-62        [-1, 240, 110, 110]               0\n",
      "           Conv2d-63        [-1, 240, 108, 108]           6,240\n",
      "      BatchNorm2d-64        [-1, 240, 108, 108]             480\n",
      "             SiLU-65        [-1, 240, 108, 108]               0\n",
      "AdaptiveAvgPool2d-66            [-1, 240, 1, 1]               0\n",
      "           Conv2d-67             [-1, 60, 1, 1]          14,460\n",
      "             SiLU-68             [-1, 60, 1, 1]               0\n",
      "           Conv2d-69            [-1, 240, 1, 1]          14,640\n",
      "          Sigmoid-70            [-1, 240, 1, 1]               0\n",
      "          SEBlock-71        [-1, 240, 108, 108]               0\n",
      "           Conv2d-72         [-1, 40, 108, 108]           9,600\n",
      "      BatchNorm2d-73         [-1, 40, 108, 108]              80\n",
      "      MBConvBlock-74         [-1, 40, 108, 108]               0\n",
      "           Conv2d-75        [-1, 240, 108, 108]           9,600\n",
      "      BatchNorm2d-76        [-1, 240, 108, 108]             480\n",
      "             SiLU-77        [-1, 240, 108, 108]               0\n",
      "           Conv2d-78        [-1, 240, 108, 108]           2,400\n",
      "      BatchNorm2d-79        [-1, 240, 108, 108]             480\n",
      "             SiLU-80        [-1, 240, 108, 108]               0\n",
      "AdaptiveAvgPool2d-81            [-1, 240, 1, 1]               0\n",
      "           Conv2d-82             [-1, 60, 1, 1]          14,460\n",
      "             SiLU-83             [-1, 60, 1, 1]               0\n",
      "           Conv2d-84            [-1, 240, 1, 1]          14,640\n",
      "          Sigmoid-85            [-1, 240, 1, 1]               0\n",
      "          SEBlock-86        [-1, 240, 108, 108]               0\n",
      "           Conv2d-87         [-1, 80, 108, 108]          19,200\n",
      "      BatchNorm2d-88         [-1, 80, 108, 108]             160\n",
      "      MBConvBlock-89         [-1, 80, 108, 108]               0\n",
      "           Conv2d-90        [-1, 480, 108, 108]          38,400\n",
      "      BatchNorm2d-91        [-1, 480, 108, 108]             960\n",
      "             SiLU-92        [-1, 480, 108, 108]               0\n",
      "           Conv2d-93        [-1, 480, 108, 108]           4,800\n",
      "      BatchNorm2d-94        [-1, 480, 108, 108]             960\n",
      "             SiLU-95        [-1, 480, 108, 108]               0\n",
      "AdaptiveAvgPool2d-96            [-1, 480, 1, 1]               0\n",
      "           Conv2d-97            [-1, 120, 1, 1]          57,720\n",
      "             SiLU-98            [-1, 120, 1, 1]               0\n",
      "           Conv2d-99            [-1, 480, 1, 1]          58,080\n",
      "         Sigmoid-100            [-1, 480, 1, 1]               0\n",
      "         SEBlock-101        [-1, 480, 108, 108]               0\n",
      "          Conv2d-102         [-1, 80, 108, 108]          38,400\n",
      "     BatchNorm2d-103         [-1, 80, 108, 108]             160\n",
      "     MBConvBlock-104         [-1, 80, 108, 108]               0\n",
      "          Conv2d-105        [-1, 480, 108, 108]          38,400\n",
      "     BatchNorm2d-106        [-1, 480, 108, 108]             960\n",
      "            SiLU-107        [-1, 480, 108, 108]               0\n",
      "          Conv2d-108        [-1, 480, 108, 108]           4,800\n",
      "     BatchNorm2d-109        [-1, 480, 108, 108]             960\n",
      "            SiLU-110        [-1, 480, 108, 108]               0\n",
      "AdaptiveAvgPool2d-111            [-1, 480, 1, 1]               0\n",
      "          Conv2d-112            [-1, 120, 1, 1]          57,720\n",
      "            SiLU-113            [-1, 120, 1, 1]               0\n",
      "          Conv2d-114            [-1, 480, 1, 1]          58,080\n",
      "         Sigmoid-115            [-1, 480, 1, 1]               0\n",
      "         SEBlock-116        [-1, 480, 108, 108]               0\n",
      "          Conv2d-117         [-1, 80, 108, 108]          38,400\n",
      "     BatchNorm2d-118         [-1, 80, 108, 108]             160\n",
      "     MBConvBlock-119         [-1, 80, 108, 108]               0\n",
      "          Conv2d-120        [-1, 480, 108, 108]          38,400\n",
      "     BatchNorm2d-121        [-1, 480, 108, 108]             960\n",
      "            SiLU-122        [-1, 480, 108, 108]               0\n",
      "          Conv2d-123        [-1, 480, 106, 106]          12,480\n",
      "     BatchNorm2d-124        [-1, 480, 106, 106]             960\n",
      "            SiLU-125        [-1, 480, 106, 106]               0\n",
      "AdaptiveAvgPool2d-126            [-1, 480, 1, 1]               0\n",
      "          Conv2d-127            [-1, 120, 1, 1]          57,720\n",
      "            SiLU-128            [-1, 120, 1, 1]               0\n",
      "          Conv2d-129            [-1, 480, 1, 1]          58,080\n",
      "         Sigmoid-130            [-1, 480, 1, 1]               0\n",
      "         SEBlock-131        [-1, 480, 106, 106]               0\n",
      "          Conv2d-132        [-1, 112, 106, 106]          53,760\n",
      "     BatchNorm2d-133        [-1, 112, 106, 106]             224\n",
      "     MBConvBlock-134        [-1, 112, 106, 106]               0\n",
      "          Conv2d-135        [-1, 672, 106, 106]          75,264\n",
      "     BatchNorm2d-136        [-1, 672, 106, 106]           1,344\n",
      "            SiLU-137        [-1, 672, 106, 106]               0\n",
      "          Conv2d-138        [-1, 672, 104, 104]          17,472\n",
      "     BatchNorm2d-139        [-1, 672, 104, 104]           1,344\n",
      "            SiLU-140        [-1, 672, 104, 104]               0\n",
      "AdaptiveAvgPool2d-141            [-1, 672, 1, 1]               0\n",
      "          Conv2d-142            [-1, 168, 1, 1]         113,064\n",
      "            SiLU-143            [-1, 168, 1, 1]               0\n",
      "          Conv2d-144            [-1, 672, 1, 1]         113,568\n",
      "         Sigmoid-145            [-1, 672, 1, 1]               0\n",
      "         SEBlock-146        [-1, 672, 104, 104]               0\n",
      "          Conv2d-147        [-1, 112, 104, 104]          75,264\n",
      "     BatchNorm2d-148        [-1, 112, 104, 104]             224\n",
      "     MBConvBlock-149        [-1, 112, 104, 104]               0\n",
      "          Conv2d-150        [-1, 672, 104, 104]          75,264\n",
      "     BatchNorm2d-151        [-1, 672, 104, 104]           1,344\n",
      "            SiLU-152        [-1, 672, 104, 104]               0\n",
      "          Conv2d-153        [-1, 672, 102, 102]          17,472\n",
      "     BatchNorm2d-154        [-1, 672, 102, 102]           1,344\n",
      "            SiLU-155        [-1, 672, 102, 102]               0\n",
      "AdaptiveAvgPool2d-156            [-1, 672, 1, 1]               0\n",
      "          Conv2d-157            [-1, 168, 1, 1]         113,064\n",
      "            SiLU-158            [-1, 168, 1, 1]               0\n",
      "          Conv2d-159            [-1, 672, 1, 1]         113,568\n",
      "         Sigmoid-160            [-1, 672, 1, 1]               0\n",
      "         SEBlock-161        [-1, 672, 102, 102]               0\n",
      "          Conv2d-162        [-1, 112, 102, 102]          75,264\n",
      "     BatchNorm2d-163        [-1, 112, 102, 102]             224\n",
      "     MBConvBlock-164        [-1, 112, 102, 102]               0\n",
      "          Conv2d-165        [-1, 672, 102, 102]          75,264\n",
      "     BatchNorm2d-166        [-1, 672, 102, 102]           1,344\n",
      "            SiLU-167        [-1, 672, 102, 102]               0\n",
      "          Conv2d-168        [-1, 672, 100, 100]          17,472\n",
      "     BatchNorm2d-169        [-1, 672, 100, 100]           1,344\n",
      "            SiLU-170        [-1, 672, 100, 100]               0\n",
      "AdaptiveAvgPool2d-171            [-1, 672, 1, 1]               0\n",
      "          Conv2d-172            [-1, 168, 1, 1]         113,064\n",
      "            SiLU-173            [-1, 168, 1, 1]               0\n",
      "          Conv2d-174            [-1, 672, 1, 1]         113,568\n",
      "         Sigmoid-175            [-1, 672, 1, 1]               0\n",
      "         SEBlock-176        [-1, 672, 100, 100]               0\n",
      "          Conv2d-177        [-1, 192, 100, 100]         129,024\n",
      "     BatchNorm2d-178        [-1, 192, 100, 100]             384\n",
      "     MBConvBlock-179        [-1, 192, 100, 100]               0\n",
      "          Conv2d-180       [-1, 1152, 100, 100]         221,184\n",
      "     BatchNorm2d-181       [-1, 1152, 100, 100]           2,304\n",
      "            SiLU-182       [-1, 1152, 100, 100]               0\n",
      "          Conv2d-183         [-1, 1152, 98, 98]          29,952\n",
      "     BatchNorm2d-184         [-1, 1152, 98, 98]           2,304\n",
      "            SiLU-185         [-1, 1152, 98, 98]               0\n",
      "AdaptiveAvgPool2d-186           [-1, 1152, 1, 1]               0\n",
      "          Conv2d-187            [-1, 288, 1, 1]         332,064\n",
      "            SiLU-188            [-1, 288, 1, 1]               0\n",
      "          Conv2d-189           [-1, 1152, 1, 1]         332,928\n",
      "         Sigmoid-190           [-1, 1152, 1, 1]               0\n",
      "         SEBlock-191         [-1, 1152, 98, 98]               0\n",
      "          Conv2d-192          [-1, 192, 98, 98]         221,184\n",
      "     BatchNorm2d-193          [-1, 192, 98, 98]             384\n",
      "     MBConvBlock-194          [-1, 192, 98, 98]               0\n",
      "          Conv2d-195         [-1, 1152, 98, 98]         221,184\n",
      "     BatchNorm2d-196         [-1, 1152, 98, 98]           2,304\n",
      "            SiLU-197         [-1, 1152, 98, 98]               0\n",
      "          Conv2d-198         [-1, 1152, 96, 96]          29,952\n",
      "     BatchNorm2d-199         [-1, 1152, 96, 96]           2,304\n",
      "            SiLU-200         [-1, 1152, 96, 96]               0\n",
      "AdaptiveAvgPool2d-201           [-1, 1152, 1, 1]               0\n",
      "          Conv2d-202            [-1, 288, 1, 1]         332,064\n",
      "            SiLU-203            [-1, 288, 1, 1]               0\n",
      "          Conv2d-204           [-1, 1152, 1, 1]         332,928\n",
      "         Sigmoid-205           [-1, 1152, 1, 1]               0\n",
      "         SEBlock-206         [-1, 1152, 96, 96]               0\n",
      "          Conv2d-207          [-1, 192, 96, 96]         221,184\n",
      "     BatchNorm2d-208          [-1, 192, 96, 96]             384\n",
      "     MBConvBlock-209          [-1, 192, 96, 96]               0\n",
      "          Conv2d-210         [-1, 1152, 96, 96]         221,184\n",
      "     BatchNorm2d-211         [-1, 1152, 96, 96]           2,304\n",
      "            SiLU-212         [-1, 1152, 96, 96]               0\n",
      "          Conv2d-213         [-1, 1152, 94, 94]          29,952\n",
      "     BatchNorm2d-214         [-1, 1152, 94, 94]           2,304\n",
      "            SiLU-215         [-1, 1152, 94, 94]               0\n",
      "AdaptiveAvgPool2d-216           [-1, 1152, 1, 1]               0\n",
      "          Conv2d-217            [-1, 288, 1, 1]         332,064\n",
      "            SiLU-218            [-1, 288, 1, 1]               0\n",
      "          Conv2d-219           [-1, 1152, 1, 1]         332,928\n",
      "         Sigmoid-220           [-1, 1152, 1, 1]               0\n",
      "         SEBlock-221         [-1, 1152, 94, 94]               0\n",
      "          Conv2d-222          [-1, 192, 94, 94]         221,184\n",
      "     BatchNorm2d-223          [-1, 192, 94, 94]             384\n",
      "     MBConvBlock-224          [-1, 192, 94, 94]               0\n",
      "          Conv2d-225         [-1, 1152, 94, 94]         221,184\n",
      "     BatchNorm2d-226         [-1, 1152, 94, 94]           2,304\n",
      "            SiLU-227         [-1, 1152, 94, 94]               0\n",
      "          Conv2d-228         [-1, 1152, 94, 94]          11,520\n",
      "     BatchNorm2d-229         [-1, 1152, 94, 94]           2,304\n",
      "            SiLU-230         [-1, 1152, 94, 94]               0\n",
      "AdaptiveAvgPool2d-231           [-1, 1152, 1, 1]               0\n",
      "          Conv2d-232            [-1, 288, 1, 1]         332,064\n",
      "            SiLU-233            [-1, 288, 1, 1]               0\n",
      "          Conv2d-234           [-1, 1152, 1, 1]         332,928\n",
      "         Sigmoid-235           [-1, 1152, 1, 1]               0\n",
      "         SEBlock-236         [-1, 1152, 94, 94]               0\n",
      "          Conv2d-237          [-1, 320, 94, 94]         368,640\n",
      "     BatchNorm2d-238          [-1, 320, 94, 94]             640\n",
      "     MBConvBlock-239          [-1, 320, 94, 94]               0\n",
      "          Conv2d-240         [-1, 1280, 94, 94]         410,880\n",
      "          Linear-241                   [-1, 10]          12,810\n",
      "================================================================\n",
      "Total params: 7,163,370\n",
      "Trainable params: 7,163,370\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 5385.20\n",
      "Params size (MB): 27.33\n",
      "Estimated Total Size (MB): 5413.10\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    x = torch.randn(4, 3, 224, 224).to(device)\n",
    "    model = efficientnet_b0().to(device)\n",
    "    output = model(x)\n",
    "    print('output size:', output.size())\n",
    "    \n",
    "    summary(model, input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_test",
   "language": "python",
   "name": "torch_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
